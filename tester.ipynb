{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|file_path|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def collect_h5_paths(root_dir, folders):\n",
    "    all_paths = []\n",
    "\n",
    "    for folder in folders:\n",
    "        base_folder_path = os.path.join(root_dir, folder)\n",
    "        for root, dirs, files in os.walk(base_folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".h5\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    all_paths.append(file_path)\n",
    "\n",
    "    return all_paths\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "root_directory = \"hdfs://host-192-168-2-83-de1:9000/user/ubuntu/MillionSongSubset\"\n",
    "directories_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "# Initialize a Spark session with Hadoop Configuration\n",
    "spark = SparkSession.builder.appName(\"H5Paths\").config(\"spark.hadoop.fs.defaultFS\", \"hdfs://host-192-168-2-83-de1:9000\").getOrCreate()\n",
    "\n",
    "all_h5_paths = collect_h5_paths(root_directory, directories_list)\n",
    "\n",
    "# Write the list of file paths to a file for debugging\n",
    "with open(\"debug_output.txt\", \"w\") as debug_file:\n",
    "    for path in all_h5_paths:\n",
    "        debug_file.write(path + \"\\n\")\n",
    "\n",
    "# Define a schema for the DataFrame\n",
    "schema = StringType()\n",
    "\n",
    "# Create a PySpark DataFrame\n",
    "h5_paths_df = spark.createDataFrame(all_h5_paths, schema=schema).toDF(\"file_path\")\n",
    "\n",
    "# Show the DataFrame\n",
    "h5_paths_df.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
